{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import os\n",
    "from tag_filter_retriever import TagFilteredFAISSRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'openbmb/MiniCPM-V-2_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minicpm初始化\n",
    "def InitLLM():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation='sdpa',\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "    return model, tokenizer\n",
    "model, tokenizer = InitLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question_and_path(text: str):\n",
    "    # 提取 Question: 和 Helpful Answer: 之间的内容\n",
    "    match = re.search(r\"Question:\\s*(.*?)\\s*Helpful Answer:\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"无法在文本中找到 Question: 和 Helpful Answer:\")\n",
    "\n",
    "    question_line = match.group(1).strip()\n",
    "\n",
    "    # 在提取到的内容中，用第一个问号分割\n",
    "    if '?' not in question_line:\n",
    "        raise ValueError(\"Question 行中不包含 '?'，无法区分问题和路径\")\n",
    "\n",
    "    idx = question_line.index('?')\n",
    "    question = question_line[:idx+1].strip()\n",
    "    image_path = question_line[idx+1:].strip()\n",
    "\n",
    "    return question, image_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain适配minicpm\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional\n",
    "\n",
    "class MiniCPM_LLM(LLM):\n",
    "    model: any\n",
    "    tokenizer: any\n",
    "    history: List = []\n",
    "\n",
    "    def _call(self, query: str, stop: Optional[List[str]] = None) -> str:\n",
    "        print(query)\n",
    "        prompt, img_src = extract_question_and_path(query)\n",
    "        image = Image.open(img_src).convert('RGB')\n",
    "        messages = [{'role': 'user', 'content': [image,prompt]}]\n",
    "        with torch.no_grad():\n",
    "            response = self.model.chat(\n",
    "                image = None,\n",
    "                tokenizer=self.tokenizer,\n",
    "                msgs=messages\n",
    "            )\n",
    "        return response\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"minicpm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取 JSON 文件\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析 JSON 数据并转换为目标格式\n",
    "def convert_img_rag_data(json_data):\n",
    "    converted_data = []\n",
    "    \n",
    "    for item in json_data:\n",
    "        img_name = item[\"img_path\"].split(\"/\")[-1].split(\"_\")[0]  # 提取图片名前缀\n",
    "        tag = \"safe\" if \"safe\" == img_name else \"unsafe\"\n",
    "        converted_data.append({\n",
    "            \"prompt\": f\"The content is about {img_name}\",\n",
    "            \"label\": \"image\",\n",
    "            \"explanation\": item[\"text\"],\n",
    "            \"embedding\": None,\n",
    "            \"src\": item[\"img_path\"],\n",
    "            \"tag\": f\"{tag}\"\n",
    "        })\n",
    "    \n",
    "    return converted_data\n",
    "\n",
    "# 读取和转换数据\n",
    "file_path = \"PATH_TO_YOUR_IMAGE_JSON\"  # json文件格式为:img_path, text(图片路径, 文本内容)\n",
    "json_data = load_json(file_path)\n",
    "img_rag_data = convert_img_rag_data(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_rag_data(jsonl_file):\n",
    "    data = []\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line.strip())  # 解析 JSONL 每一行\n",
    "            label_text = ', '.join(item[\"label\"])  # 处理 label 列表为字符串\n",
    "            tag = \"safe\" if \"safe\" in label_text else \"unsafe\"\n",
    "            formatted_item = {\n",
    "                \"prompt\": f\"The content is about {label_text}\",\n",
    "                \"label\": \"text\",\n",
    "                \"explanation\": item[\"text\"],\n",
    "                \"embedding\": None,\n",
    "                \"src\": \"\",\n",
    "                \"tag\": f\"{tag}\"\n",
    "            }\n",
    "            data.append(formatted_item)\n",
    "    return data\n",
    "\n",
    "# 示例调用\n",
    "jsonl_file = \"PATH_TO_YOUR_TEXT_JSONL\"  # 你的 JSONL 文件:text, label \n",
    "text_rag_data = convert_text_rag_data(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、加载clip模型\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 构建RAG数据\n",
    "data = img_rag_data + text_rag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, max_length=77):\n",
    "    \"\"\"截断文本，确保不超过 max_length 个 token\"\"\"\n",
    "    tokens = clip_processor.tokenizer.encode(text, add_special_tokens=True)\n",
    "    if len(tokens) > max_length:\n",
    "        tokens = tokens[:max_length-1] + [clip_processor.tokenizer.eos_token_id]  # 截断并加上结束符\n",
    "    return clip_processor.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 计算文本和图像的 CLIP 嵌入\n",
    "def get_clip_embedding(item):\n",
    "    \n",
    "    #引入文本截断，防止文本过长\n",
    "    if item[\"label\"] == \"text\":\n",
    "        # 文本嵌入\n",
    "        truncated_text = truncate_text(item[\"explanation\"])  # 先截断文本\n",
    "        inputs = clip_processor(text=truncated_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            text_embedding = clip_model.get_text_features(**inputs)\n",
    "        return text_embedding.squeeze().cpu().tolist()\n",
    "\n",
    "    elif item[\"label\"] == \"image\":\n",
    "        # 图像嵌入\n",
    "        image_path = item[\"src\"]\n",
    "        if os.path.exists(image_path):\n",
    "            image = Image.open(image_path)\n",
    "            inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                image_embedding = clip_model.get_image_features(**inputs)\n",
    "            return image_embedding.squeeze().cpu().tolist()\n",
    "        else:\n",
    "            print(f\"⚠️: 图像 {image_path} 不存在，使用零向量代替！\")\n",
    "            return [0.0] * 512  # 图像不存在时用 0 填充\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"未知的数据类型: {item['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 计算嵌入并存储\n",
    "from tqdm import tqdm\n",
    "\n",
    "for item in tqdm(data, desc=\"Processing items\"):\n",
    "    item[\"embedding\"] = get_clip_embedding(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 保存数据到 JSON 文件\n",
    "with open(\"rag_data.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# 自定义 CLIPEmbedding 类\n",
    "class CLIPEmbedding(Embeddings):\n",
    "    def __init__(self, clip_model, clip_processor):\n",
    "        self.clip_model = clip_model\n",
    "        self.clip_processor = clip_processor\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.clip_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.clip_model.get_text_features(**inputs).cpu().numpy()\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        inputs = self.clip_processor(text=query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.clip_model.get_text_features(**inputs).squeeze().cpu().numpy()\n",
    "        return embedding.tolist()\n",
    "    \n",
    "    def embed_image_query(self, img_src):\n",
    "        image = Image.open(img_src)\n",
    "        inputs = self.clip_processor(images=image, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.clip_model.get_image_features(**inputs).squeeze().cpu().numpy()\n",
    "        return embedding.tolist()\n",
    "\n",
    "# 使用 CLIPEmbedding\n",
    "clip_embeddings = CLIPEmbedding(clip_model, clip_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 构建包含元数据的faiss对象\n",
    "from langchain.schema import Document\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "docs = []\n",
    "vectors = []\n",
    "\n",
    "for item in data:\n",
    "    content = item[\"prompt\"] + \"\\n\" + item[\"explanation\"] + \"\\n\" + item[\"label\"] + \"\\n\" + item[\"src\"] + \"\\n\" + item[\"tag\"]\n",
    "    metadata = {\n",
    "        \"tag\": item[\"tag\"],\n",
    "        \"src\": item[\"src\"]\n",
    "    }\n",
    "    docs.append(Document(page_content=content, metadata=metadata))\n",
    "    vectors.append(item[\"embedding\"])\n",
    "\n",
    "# 转为 numpy array\n",
    "embeddings = np.array(vectors).astype(\"float32\")\n",
    "\n",
    "# 构造 faiss index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "\n",
    "docstore = InMemoryDocstore(dict(enumerate(docs)))  \n",
    "index_to_docstore_id = {i: i for i in range(len(docs))}\n",
    "\n",
    "# 构造 FAISS 存储对象\n",
    "faiss_store_filter = FAISS(\n",
    "    embedding_function=clip_embeddings,  \n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id={i: i for i in range(len(docs))}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存faiss索引\n",
    "faiss_store_filter.save_local(\"guard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 构建 RAG 处理链\n",
    "retriever_filter = faiss_store_filter.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever_tag = TagFilteredFAISSRetriever(\n",
    "    faiss_store=faiss_store_filter,\n",
    "    embedding_model=clip_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# 7. 加载 MiniCPM模型\n",
    "\n",
    "llm = MiniCPM_LLM(model = model, tokenizer = tokenizer)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_filter, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 使用 Minicpm 进行单图安全评估\n",
    "def evaluate_safety(prompt: str = \"describe this in a word\", img_src: str = \"none\"):\n",
    "    if(img_src == \"none\"):\n",
    "        img_src = 'blank.jpg'\n",
    "    image = Image.open(img_src).convert('RGB')\n",
    "    prompt = \"describe this in a word:\" + prompt + \"your answer must be one of the categories:[safe, violence, self-harm, nude, illegal-religion, animal-cruelty, schoolbullying, sex, terrorism, privacy]\"\n",
    "    msgs = [{'role': 'user', 'content': [image, prompt]}]\n",
    "\n",
    "    res = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要检测的敏感词列表\n",
    "sensitive_terms = [\"violence\", \"self-harm\", \"nude\", \"illegal-religion\",\n",
    "              \"animal-cruelty\", \"schoolbullying\", \"sex\", \"terrorism\", \"privacy\"]\n",
    "# 将敏感词转为一个正则表达式，忽略大小写\n",
    "pattern = r'|'.join([re.escape(term) for term in sensitive_terms])\n",
    "# 检测文本\n",
    "def check_sensitive_content(text):\n",
    "    text_lower = text.lower()  # 转小写进行不区分大小写的匹配\n",
    "    matches = re.findall(pattern, text_lower, flags=re.IGNORECASE)\n",
    "    if matches:\n",
    "        return set(matches)  # 返回匹配到的敏感词\n",
    "    else:\n",
    "        return \"safe\"  # 没有匹配到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#多图检索\n",
    "def multi_image_inference(image_paths, model, tokenizer, reference_tag = 0, unsafe_tag = 'safe', img_tag = 'safe'):\n",
    "    \"\"\"\n",
    "    多图推理函数，支持自动构造提示语，描述最后一张图片。\n",
    "    \n",
    "    参数：\n",
    "        image_paths (list[str]): 图像路径数组\n",
    "        model: 加载好的模型\n",
    "        tokenizer: 加载好的 tokenizer\n",
    "        reference_tag: 参考图片的索引\n",
    "        unsafe_tag: 参考图片的安全类别\n",
    "        img_tag: 目标图片的疑似类别\n",
    "\n",
    "    返回：\n",
    "        answer (str): 推理生成的描述\n",
    "    \"\"\"\n",
    "    assert len(image_paths) >= 1, \"至少需要提供一张图片\"\n",
    "    \n",
    "    # 打开所有图片\n",
    "    images = [Image.open(p).convert(\"RGB\") for p in image_paths]\n",
    "\n",
    "    # 构造提示语\n",
    "    if len(images) == 1:\n",
    "        question = \"Describe this image with one word.\"\n",
    "        msgs = [{'role': 'user', 'content': [images[0], question]}]\n",
    "    else:\n",
    "        ref_images = images[:-1]\n",
    "        target_image = images[-1]\n",
    "        ref_str = \", \".join([f\"image{i+1}\" for i in range(len(ref_images))])\n",
    "        \n",
    "        # 判断是否加入初步预测强化\n",
    "        if img_tag == unsafe_tag:\n",
    "            tag_hint = (\n",
    "                f\"\\nImage{reference_tag+1} is visually highly similar to image{len(images)}, \"\n",
    "                f\"and both appear to contain content consistent with the '{img_tag}' category.\\n\"\n",
    "                f\"Based on this strong similarity, and initial prediction results, \"\n",
    "                f\"it is highly likely that image{len(images)} also belongs to the '{img_tag}' category.\\n\"\n",
    "                f\"Use this information to guide your classification, especially if any content in image{len(images)} is ambiguous.\\n\"\n",
    "                f\"However, base your final classification on the actual visual content of image{len(images)}.\"\n",
    "            )\n",
    "        else:\n",
    "            tag_hint = \"\"\n",
    "        \n",
    "        question = (\n",
    "            f\"Your task is to classify the content of image{len(images)} into one of the following categories:\\n\"\n",
    "            f\"[safe, violence, self-harm, nude, illegal-religion, animal-cruelty, schoolbullying, sex, terrorism, privacy].\\n\\n\"\n",
    "            f\"You are given five images: {ref_str} and image{len(images)}.\\n\"\n",
    "            f\"Among image1 to image{len(images)-1} (reference images), only image{reference_tag+1} is highly relevant and should be used as the main reference.\\n\"\n",
    "            f\"image{reference_tag+1} belongs to the '{unsafe_tag}' category.\\n\"\n",
    "            f\"Ignore the content of the other reference images.\\n\\n\"\n",
    "            f\"Use image{reference_tag+1} only to assist in understanding ambiguous or unclear regions in image{len(images)}.\\n\"\n",
    "            f\"Focus primarily on the actual content of image{len(images)} when making your classification decision.\\n\\n\"\n",
    "            f\"{tag_hint}\\n\\n\"\n",
    "            \n",
    "            f\"Respond with exactly one word from the category list.\"\n",
    "        )\n",
    "        \n",
    "        msgs = [{'role': 'user', 'content': ref_images + [target_image, question]}]\n",
    "    # 推理生成答案\n",
    "    answer = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    return answer, question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多文本推理\n",
    "def multi_text_inference(texts, model, tokenizer, reference_tag = 0, unsafe_tag = \"safe\", txt_tag=\"safe\"):\n",
    "    \"\"\"\n",
    "    多文本推理函数，支持自动构造提示语，描述最后一段文本。\n",
    "\n",
    "    参数：\n",
    "        texts (list[str]): 文本数组，前面的为参考，最后一个为要描述的对象。\n",
    "        model: 加载好的模型\n",
    "        tokenizer: 加载好的 tokenizer\n",
    "        reference_tag: 参考文本的索引\n",
    "        unsafe_tag: 参考文本的安全类别\n",
    "        txt_tag: 目标文本的疑似类别\n",
    "\n",
    "    返回：\n",
    "        answer (str): 推理生成的描述\n",
    "    \"\"\"\n",
    "    assert len(texts) >= 1, \"至少需要提供一段文本\"\n",
    "\n",
    "    image_path = 'blank.jpg'\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    if len(texts) == 1:\n",
    "        question = \"Describe the following text with one word:\\n'\" + texts[0] + \"'\"\n",
    "        msgs = [{'role': 'user', 'content': [img, question]}]\n",
    "    else:\n",
    "        ref_texts = texts[:-1]\n",
    "        target_text = texts[-1]\n",
    "        ref_str = \", \".join([f'\"{t}\"' for t in ref_texts])\n",
    "        ref_text = ref_texts[reference_tag] #相似度最高的参考文本\n",
    "        \n",
    "        if txt_tag == unsafe_tag:\n",
    "            tag_hint = (\n",
    "                f\"\\nThe reference text \\\"{ref_text}\\\" is highly similar to the target text and belongs to the '{unsafe_tag}' category.\\n\"\n",
    "                f\"Based on this strong similarity and prior indications, it is highly likely that the target text also falls into the '{txt_tag}' category.\\n\"\n",
    "                f\"Use this information to guide your classification, especially if the target text is ambiguous.\\n\"\n",
    "                f\"However, base your final decision strictly on the actual content of the target text.\"\n",
    "            )\n",
    "        else:\n",
    "            tag_hint = \"\"\n",
    "        \n",
    "        question = (\n",
    "            f\"Your task is to classify the target text into one of the following categories:\\n\"\n",
    "            f\"[safe, violence, self-harm, nude, illegal-religion, animal-cruelty, schoolbullying, sex, terrorism, privacy].\\n\\n\"\n",
    "            f\"You are given several reference texts: {ref_str}.\\n\"\n",
    "            f\"Among them, only the reference text \\\"{ref_text}\\\" is highly relevant and should be used as the main reference.\\n\"\n",
    "            f\"It belongs to the '{unsafe_tag}' category.\\n\"\n",
    "            f\"Ignore the content of the other reference texts.\\n\\n\"\n",
    "            f\"Use the main reference text only to assist in understanding ambiguous or unclear parts of the target text.\\n\"\n",
    "            f\"Focus primarily on the actual content of the target text when making your classification decision.\"\n",
    "            f\"{tag_hint}\\n\\n\"\n",
    "            f\"Target text: \\\"{target_text}\\\"\\n\"\n",
    "            f\"Respond with exactly one word from the category list.\"\n",
    "        )\n",
    "        \n",
    "        msgs = [{'role': 'user', 'content': [img, question]}]\n",
    "    # 推理生成答案\n",
    "    answer = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    return answer, question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_rag(query, top_k = 2):\n",
    "    try:\n",
    "        image = Image.open(query)\n",
    "        unsafe_docs, unsafe_score = retriever_tag.search(img_src = query, tag = 'unsafe', top_k = top_k)\n",
    "        safe_docs, safe_score = retriever_tag.search(img_src = query, tag = 'safe', top_k = top_k)\n",
    "        docs = unsafe_docs + safe_docs\n",
    "        \n",
    "    except:\n",
    "        unsafe_docs, unsafe_score = retriever_tag.search(query = query, tag = 'unsafe', top_k = top_k)\n",
    "        safe_docs, safe_score = retriever_tag.search(query = query, tag = 'safe', top_k = top_k)\n",
    "        docs = unsafe_docs + safe_docs\n",
    "    \n",
    "    descripe_list = [] # 检索出来相关内容的说明\n",
    "    image_paths = [] # 检索出来的相关图片地址\n",
    "    \n",
    "    #  输出检索结果\n",
    "    for i, doc in enumerate(docs):\n",
    "        lines = doc.page_content.split(\"\\n\")\n",
    "        result_discripe = lines[1]\n",
    "        result_img_src = lines[3]\n",
    "        descripe_list.append(result_discripe)\n",
    "        image_paths.append(result_img_src)\n",
    "    \n",
    "    reference_tag = 0\n",
    "    if(unsafe_score <= safe_score):\n",
    "        citation = \"# Unsafe example 1\"\n",
    "        unsafe_status = next(iter(check_sensitive_content(descripe_list[0])))\n",
    "    else:\n",
    "        citation = \"# Safe example 1\"\n",
    "        unsafe_status = \"safe\"\n",
    "        reference_tag = 2\n",
    "        \n",
    "    try:\n",
    "        image = Image.open(image_paths[0])\n",
    "        \n",
    "        print(query)\n",
    "        \n",
    "        print(\"<BEGIN IMAGE EXAMPLES>\")\n",
    "        \n",
    "        for idx, result_img_src in enumerate(image_paths):\n",
    "            try:\n",
    "                image = Image.open(result_img_src)  # 打开图片\n",
    "                if(idx < 2):\n",
    "                    print(f\"# Unsafe example {idx+1}:\\nimg_src: {result_img_src}\")  # 打印参考图片的编号\n",
    "                else:\n",
    "                    print(f\"# Safe example {idx+1}:\\nimg_src: {result_img_src}\")  # 打印参考图片的编号\n",
    "                # image.show()  # 展示图片\n",
    "                \n",
    "                sensitive_word = check_sensitive_content(descripe_list[idx])\n",
    "                \n",
    "                if(sensitive_word != \"safe\"):\n",
    "                    print(f\"Assessment: Unsafe - {next(iter(sensitive_word))}\\nExplanation: {descripe_list[idx]}\\n\\n\")\n",
    "                else:\n",
    "                    print(f\"Assessment: Safe\\nExplanation: {descripe_list[idx]}\\n\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"无法打开图片 {result_img_src}: {e}\")   \n",
    "        print(\"<END IMAGE EXAMPLES>\")\n",
    "        \n",
    "        image_paths.append(query)\n",
    "        \n",
    "        img_tag = evaluate_safety(prompt='describe this in a word', img_src = query)\n",
    "        \n",
    "        response, _ = multi_image_inference(image_paths, model, tokenizer, reference_tag, unsafe_status, img_tag)\n",
    "        print('============================================LLM-RAG============================================')\n",
    "        print(f\"Safe Status: {response}\\nCitation: {citation}\\n\")\n",
    "        print(f\"- {descripe_list[reference_tag]}\")\n",
    "        print('==============================================END==============================================')\n",
    "        \n",
    "    #文本检索    \n",
    "    except:\n",
    "        print(f\"User text:{query}\\n\\n\")\n",
    "        print(\"<BEGIN TEXT EXAMPLES>\")\n",
    "        \n",
    "        for idx, result_img_src in enumerate(descripe_list):\n",
    "            \n",
    "            if(idx < 2):\n",
    "                    print(f\"# Unsafe example {idx+1}:\\n\")  \n",
    "            else:\n",
    "                print(f\"# Safe example {idx+1}:\\n\")  \n",
    "            \n",
    "            sensitive_word = check_sensitive_content(descripe_list[idx])\n",
    "            \n",
    "            if(sensitive_word != 'safe'):\n",
    "                print(f\"Text content: {descripe_list[idx]}\\nAssessment: Unsafe - {next(iter(sensitive_word))}\\n\\n\")\n",
    "            else:\n",
    "                print(f\"Text content: {descripe_list[idx]}\\nAssessment: Safe\\n\\n\")\n",
    "                    \n",
    "           \n",
    "        print(\"<END TEXT EXAMPLES>\")\n",
    "        \n",
    "        descripe_list.append(query)\n",
    "        txt_tag = evaluate_safety(prompt=query)\n",
    "            \n",
    "        response, _ = multi_text_inference(descripe_list, model, tokenizer, reference_tag, unsafe_status, txt_tag)\n",
    "        print('============================================LLM-RAG============================================')\n",
    "        print(f\"Safe Status: {response}\\nCitation: {citation}\\n\") \n",
    "        print(f\"- {descripe_list[reference_tag]}\")\n",
    "        print('==============================================END==============================================')\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minicpm图片推理测试\n",
    "img_src = 'schoolbullying_10.jpg'\n",
    "print(\"============================================需要识别的图片为============================================\")\n",
    "try:\n",
    "    image = Image.open(img_src)  # 打开图片\n",
    "    image.show()  # 展示图片\n",
    "except Exception as e:\n",
    "    print(f\"无法打开图片 {img_src}: {e}\")\n",
    "    \n",
    "print(\"===============================================RAG===============================================\")\n",
    "search_rag(img_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rag('He was arrested for being publicly nude.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
